	基础环境准备

	linux-node1.example.com 安装

	# Base
	linux-node1.example.com    192.168.56.11    控制节点
	linux-node2.example.com    192.168.56.12    计算节点

	需要配置主机名解析
	vim /etc/hosts
	192.168.56.11    linux-node1    linux-node1.example.com        控制节点
	192.168.56.12    linux-node2    linux-node2.example.com        计算节点

	时间和主机名的部署在云环境当中非常重要（事件必须同步）
	yum -y install chrony

	vim /etc/chrony.conf  # 编辑配置文件
	allow 192.168/16   // 允许那些地址段来访问

	systemctl start chronyd.service
	systemctl enable chronyd.service

	# 设置时区
	timedatectl set-timezone Asia/Shanghai
	date
	Sat Dec 12 11:05:31 CST 2017

	# 为centos安装epel源
	Base:
		yum install -y http://dl.fedoraproject.org/pub/epel/7/x86_64/e/epel-release-7-5.noarch.rpm
		yum install centos-release-openstack-liberty
		yum install python-openstackclient


	/*
	 * 阿里云官方openstack源的地址是: mirrors.aliyun.com/centos/7.1.1503/cloud/x86_64/openstack-liberty/
	 */


	MySQL:
		yum install -y mariadb-server MySQL-python

		# 拷贝mysql的配置文件
		cp /usr/share/mysql/my-medium.cnf /etc/my.cnf
		
		vim /etc/my.cnf
		[mysqld]
		default-storage-engine = innodb
		innodb_file_per_table
		collation-server = utf8_general_ci
		init-connect = 'SET NAMES utf8'
		character-set-server = utf8
		port = 3306
		socket = /var/lib/mysql/mysql.sock

		systemctl enable mariadb.service
		systemctl start mariadb.service
		# 为mysql设置root密码
		mysql secure installation

		mysql -uroot -p -e 'CREATE DATABASE keystone;'
		mysql -uroot -p -e "GRANT ALL PRIVILEGES ON keystone.* TO 'keystone'@'localhost' IDENTIFIED BY 'keystone';"
		mysql -uroot -p -e "GRANT ALL PRIVILEGES ON keystone.* TO 'keystone'@'%' IDENTIFIED BY 'keystone';"

		mysql -uroot -p -e 'CREATE DATABASE glance;'
		mysql -uroot -p -e "GRANT ALL PRIVILEGES ON glance.* TO 'glance'@'localhost' IDENTIFIED BY 'glance';"
		mysql -uroot -p -e "GRANT ALL PRIVILEGES ON glance.* TO 'glance'@'%' IDENTIFIED BY 'glance';"

		mysql -uroot -p -e 'CREATE DATABASE nova;'
		mysql -uroot -p -e "GRANT ALL PRIVILEGES ON nova.* TO 'nova'@'localhost' IDENTIFIED BY 'nova';"
		mysql -uroot -p -e "GRANT ALL PRIVILEGES ON nova.* TO 'nova'@'%' IDENTIFIED BY 'nova';"

		mysql -uroot -p -e 'CREATE DATABASE neutron;'
		mysql -uroot -p -e "GRANT ALL PRIVILEGES ON neutron.* TO 'neutron'@'localhost' IDENTIFIED BY 'neutron';"
		mysql -uroot -p -e "GRANT ALL PRIVILEGES ON neutron.* TO 'neutron'@'%' IDENTIFIED BY 'neutron';"

		mysql -uroot -p -e 'CREATE DATABASE cinder;'
		mysql -uroot -p -e "GRANT ALL PRIVILEGES ON cinder.* TO 'cinder'@'localhost' IDENTIFIED BY 'cinder';"
		mysql -uroot -p -e "GRANT ALL PRIVILEGES ON cinder.* TO 'cinder'@'%' IDENTIFIED BY 'cinder';"


	RabbitMQ:
		yum install -y rabbitmq-server

		systemctl start rabbitmq-server.service
		systemctl enable rabbitmq-server.service

		# 创建一个openstack的专属用户并授权让其使用,并启用管理插件
		rabbitmqctl add_user openstack openstack
		rabbitmqctl set_permissions openstack ".*" ".*" ".*"
		rabbitmq-plugins enable rabbitmq_management

		systemctl restart rabbitmq-server.service



	'''
		openstack 组件安装
	'''

	Keystone: 认证服务
		yum install -y openstack-keystone httpd mod-wsgi memcached python-memcached

		vim /etc/keystone/keystone.conf

		[DEFAULT] # 设置默认的token
		admin_token = 863d35676a5632e846d9

		[database] # 设置数据库(用户名/密码/ip地址/数据库名) 填写完成之后wq保存退出执行一条命令对数据库做同步
		cocnnection = mysql://keystone:keystone@192.168.56.11/keystone
		su -s /bin/sh -c "keystone-manage db_sync" keystone

		vim /etc/keystone/keystone.conf
		[memcache] # 设置memcache的访问地址
		servers = 192.168.56.11:11211

		[token] # 设置token的存储方式
		provider = uuid
		driver = memcache

		[revoke] # sql回滚功能
		driver = sql

		[verbose] # 程序debug开关
		verbose = true

		# 配置完成keystone，启动该服务
		systemctl start memcached.service

		# 新建keystone 配置文件
		vim /etc/httpd/conf.d/wsgi-keystone.conf
		Listen 5000  # 正常访问端口
		Listen 35357 # admin管理端

		<VirtualHost *:5000>
			WSGIDaemonProcess keystone-public processes=5 threads=1 user=keystone group=keystone diaplay-name=%{GROUP}
			WSGIProcessGroup keystone-public
			WSGIScriptAlias / /usr/bin/keystone-wsgi-public
			WSGIApplicationGroup %{GLOBAL}
			WSGIPassAuthorization On
			<IfVersion >= 2.4>
				ErrorLogFormat "%{cu}t %M"
			</IfVersion>
			ErrorLog /var/log/httpd/keystone-error.log
			CustomLog /var/log/httpd/keystone-access.log combined

			<Directory /usr/bin>
				<IfVersion >= 2.4>
					Require all granted
				</IfVersion>
				<IfVersion < 2.4>
					Order allow,deny
					Allow from all
				</IfVersion>
			</Directory>
		</VirtualHost>

		<VirtualHost *:35357>
			WSGIDaemonProcess keystone-public processes=5 threads=1 user=keystone group=keystone diaplay-name=%{GROUP}
			WSGIProcessGroup keystone-public
			WSGIScriptAlias / /usr/bin/keystone-wsgi-public
			WSGIApplicationGroup %{GLOBAL}
			WSGIPassAuthorization On
			<IfVersion >= 2.4>
				ErrorLogFormat "%{cu}t %M"
			</IfVersion>
			ErrorLog /var/log/httpd/keystone-error.log
			CustomLog /var/log/httpd/keystone-access.log combined

			<Directory /usr/bin>
				<IfVersion >= 2.4>
					Require all granted
				</IfVersion>
				<IfVersion < 2.4>
					Order allow,deny
					Allow from all
				</IfVersion>
			</Directory>
		</VirtualHost>

		保存退出

		# 配置完成以上之后，还需要在httpd主配置文件编辑ServerName(如果不配置该字段keystone服务将不能启动) 
		vim /etc/httpd/conf/httpd.conf
		ServerName 192.168.56.11:80  
		
		systemctl enable httpd.service
		systemctl start httpd.service
 
		netstat -tunlp | grep httpd  # 看到以下有端口启动说明keystone服务启动正常
		......:5000
		......:80
		......:35357

		# 运行keystone创建用户
		export OS_TOKEN=863d35676a5632e846d9
		export OS_URL=http://192.168.56.11:35357/v3
		export OS_IDENTITY_API_VERSION=3

		openstack user list   # 查看当前keystone生成的用户

		# 创建admin的用户
		openstack project create --domain default --description “Admin Project” admin # 创建一个项目,创建完成之后会生成一个id
		openstack user create --domain default --password-prompt admin # 会让你输入密码的
		openstack role create admin # 创建一个admin的角色
		openstack role add --project admin --user admin admin # 关联admin用户的权限

		# 使用普通用户来用于虚拟机的创建
		openstack project create --domain default --description "Demo Project" demo
		openstack user create --domain default --password=demo demo
		openstack role create user
		openstack role add --project demo --user demo user

		# 创建一个叫service项目
		openstack project createe --domain default --description "Service Project" service

		# 使用 openstack project list 可以查看创建了多少个项目
		openstack project list
		......

		# openstack 创建一个服务(并配置keystone可以连接service)
		openstack service create --name keystone --description "OpenStack Identity" identity
		openstack endpoint create --region RegionOne identity public http://192.168.56.11:5000/v2.0
		openstack endpoint create --region RegionOne identity internal http://192.168.56.11:5000/v2.0
		openstack endpoint create --region RegionOne identity admin http://192.168.56.11:35357/v2.0
		
		# 因为已经配置好了用户名和密码所以把 admin当中配置token的环境变量给去掉
		unset OS_TOKEN
		unset OS_URL

		openstack --os-auth-url http://192.168.56.11:35357/v3 --os-project-domain-id default --os-user-domain-id default --os-project-name admin --os-username admin --os-auth-type password token issue

		# 但是以上情况配置太过于繁琐和麻每次都要输入用户名和密码，所以可以配置keystone 环境变量, 方便执行命令,不需要每次都去执行
		vim admin-openrc.sh
		export OS_PROJECT_DOMAIN_ID=default
		export OS_USER_DOMAIN_ID=default
		export OS_PROJECT_NAME=admin
		export OS_TENANT_NAME=admin
		export OS_USERNAME=admin
		export OS_PASSWORD=admin
		export OS_AUTH_URL=http://192.168.56.11:35357/v3
		export OS_IDENTITY_API_VERSION=3

		vim demo-openrc.sh
		export OS_PROJECT_DOMAIN_ID=default
		export OS_USER_DOMAIN_ID=default
		export OS_PROJECT_NAME=demo
		export OS_TENANT_NAME=demo
		export OS_USERNAME=demo
		export OS_PASSWORD=demo
		export OS_AUTH_URL=http://192.168.56.11:5000/v3
		export OS_IDENTITY_API_VERSION=3

		保存退出，只需要source以下该文件即可
		chmod +x admin-openrc.sh demo-openrc.sh
		source admin-openrc.sh
		openstack token issue
		......



	Glance: 镜像服务
		Glance主要由三个部分构成：glance-api, glance-registry 以及 image store
		Glance-api：接受云系统镜像的创建，删除，读取请求
		Glance-Registry：云系统的镜像注册服务
		yum install -y openstack-glance python-glance python-glanceclient
		
		vim /etc/glance/glance-api.conf
		[database]
		connection=mysql://glance:glance@192.168.56.11/glance
		保存退出
		
		vim /etc/glance/glance-registry.conf
		[database]
		connection=mysql://glance:glance@192.168.56.11/glance
		保存退出

		su -s /bin/sh -c "glance-manage db_sync" glance # 同步数据库

		# 执行完成之后需要为glance创建一个用户
		openstack user create --domain default --password=glance glance
		openstack role add --project service --user glance admin

		# 创建完成用户并给其授权之后在keystone当中去注册，在次编辑 vim /etc/glance/glance-api.conf 文件
		vim /etc/glance/glance-api.conf
		[keystone_authtoken]
		auth_uri = http://192.168.56.11:5000
		auth_uri = http://192.168.56.11:35357
		auth_plugin = password
		project_domain_id = default
		user_domain_id = default
		project_name = service
		username = glance
		password = glance

		# 在解析当中配置使用keystone
		[paste_deploy]
		flavor=keystone

		# 由于glance 组件不需要用到中间件，所以把通知选项给设置成为noop
		notification_driver = noop

		# 设置镜像存储的位置
		[glance_store]
		default_store=file # 存放类型
		filesystem_store_datadir=/var/lib/glance/images/ # 存放位置
		verbose=True
		保存退出
		
		vim /etc/glance/glance-registry.conf
		[keystone_authtoken]
		auth_uri = http://192.168.56.11:5000
		auth_uri = http://192.168.56.11:35357
		auth_plugin = password
		project_domain_id = default
		user_domain_id = default
		project_name = service
		username = glance
		password = glance

		# 在解析当中配置使用keystone
		[paste_deploy]
		flavor=keystone
		保存退出


		# 启动glance服务
		systemctl enable openstack-glance-api
		systemctl enable openstack-glance-registry
		systemctl start openstack-glance-api
		systemctl start openstack-glance-registry

		netstat -tunlp 
		......:9292 # registry
		......:9191 # api

		openstack service create --name glance --description "OpenStack Image service" image
		openstack endpoint create --region RegionOne image public http://192.168.56.11:9292
		openstack endpoint create --region RegionOne image internal http://192.168.56.11:9292
		openstack endpoint create --region RegionOne image admin http://192.168.56.11:9292

		
		echo "export OS_IMAGE_API_VERSION=2" | tee -a admin-openrc.sh demo-openrc.sh

		# 执行 glance image-list 命令如果成功就代表glance 组件注册成功
		glance image-list
		......

		# 接下来，需要先下载一个小的镜像，当做一个虚拟机镜像进行安装即可
		wget http://download.cirros-cloud.net/0.3.4/cirror-0.3.4-x86_64-disk.img

		# 下载完成之后，上传一个镜像到本地
		glance image-create --name "cirros" --file cirros-0.3.4-x86_64-disk.img --disk-format qcow2 --container-format bare --visibility public --progress

		glance image-list # 查看镜像会看有刚才上传的镜像的信息
		---------------------------------------------------------------
		|  ID												|  Name   |
		---------------------------------------------------------------
		|  5f5058b0-209b-4e9d-a9e6-c15c09527454				|  cirros |
		---------------------------------------------------------------

		cd /var/lib/glance/images/
		ls 
		......  # 会看到刚才的镜像的id和该目录当中的文件名一样，说明创建成功


	

	Nova: 控制节点
		API: 负责接收和响应外部请求。支持OpenStack API， EC2API
		Cert：负责身份认证
		Scheduler：用于云主机调度
		Conductor：计算节点访问数据的中间件
		Consoleauth：用于控制台的授权验证
		Novncproxy：VNC代理

		Nova API: 实现了restful API功能。是外部访问nova的唯一途径。
		接收外部的请求并通过 Message Queue 将请求发送给其它的服务组件，同时也兼容EC2 API，所以也可以用EC2的管理工具对nova进行日常管理

		Nova scheduler: 决策虚拟机创建在哪个主机（计算节点）上。
			决策一个虚拟机应该调度到某物理节点，需要分两个步骤
				过滤 Filter
				计算权值 Weight

				1.数据库
				2.keystone
				3.rabbitmq
				4.网络相关


		yum -y install openstack-nove-api openstack-nova-cert openstack-nova-conductor openstack-nova-console openstack-nova-novncproxy openstack-nova-scheduler python-novaclient

		# 安装完成之后编辑配置文件 /etc/nova/nova.conf
		vim /etc/nova/nova.conf
		[database]
		connection=mysql://nova:nova@192.168.56.11/nova
		保存退出

		su -s /bin/sh -c "nova-manage db sync" nova

		vim /etc/nova/nova.conf
		[DEFAULT]
		rpc_backend=rabbit

		[oslo_messaging_rabbit]
		rabbit_host=192.168.56.11
		rabbit_port=5672
		rabbit_userid=openstack
		rabbit_password=openstack

		保存退出，并创建一个能让nova使用的用户


		source admin-openrc.sh
		openstack user create --domain default --password=nova nova
		openstack role add --project service --user nova admin

		vim /etc/nova/nova.conf
		[keystone_authtoken]
		auth_uri = http://192.168.56.11:5000
		auth_uri = http://192.168.56.11:35357
		auth_plugin = password
		project_domain_id = default
		user_domain_id = default
		project_name = service
		username = nova
		password = nova

		[DEFAULT]
		auth_strategy=keystone

		network_api_class=nova.network.neutronv2.api.API
		security_group_api=neutron
		linuxnet_interface_driver=nova.network.linux_net.NeutronLinuxBridgeInterfaceDriver
		firewall_driver=nova.virt.firewall.NoopFirewallDriver
		my_ip=192.168.56.11
		vncserver_listen=$my_ip
		vncserver_proxyclient_address=$my_ip

		[glance]
		host=$my_ip

		lock_path=/var/lib/nova/tmp
		enabled_apis=osapi_compute,metadata

		保存退出

		systemctl enable openstack-nova-api.service openstack-nova-cert.service openstack-nova-consoleauth.service openstack-nova-scheduler.service openstack-nova-conductor.service openstack-nova-novncproxy.service

		systemctl start openstack-nova-api.service openstack-nova-cert.service openstack-nova-consoleauth.service openstack-nova-scheduler.service openstack-nova-conductor.service openstack-nova-novncproxy.service

		openstack service create --name nova --description "OpenStack Compute" compute
		openstack endpoint create --region RegionOne compute public http://192.168.56.11:8774/v2/%\(tenant_id\)s
		openstack endpoint create --region RegionOne compute internal http://192.168.56.11:8774/v2/%\(tenant_id\)s
		openstack endpoint create --region RegionOne compute admin http://192.168.56.11:8774/v2/%\(tenant_id\)s

		openstack host list
		--------------------------------------------------------------------
		| Host Name                         | Service       | Zone         |
		--------------------------------------------------------------------
		| linux-node1.oldboyedu.com         | conductor     | internal     |
		| linux-node1.oldboyedu.com         | scheduler     | internal     |
		| linux-node1.oldboyedu.com         | consoleauth   | internal     |
		| linux-node1.oldboyedu.com         | cert          | internal     |
		--------------------------------------------------------------------


		# nova 计算节点的搭建
		scp /etc/nova/nova.conf  root@192.168.56.12:/etc/nova
		...

		# 在linux-node2节点上
		yum -y install openstack-nova-compute sysfsutils

		vim /etc/nova/nova.conf
		my_ip=192.168.56.12
		novncproxy_base_url=http://192.168.56.11:6080/vnc_auto.html
		vncserver_listen=0.0.0.0
		vncserver_proxyclient_address=$my_ip
		vnc_enabled=true
		vnc_keymap=en-us

		[glance]
		host=192.168.56.11
		virt_type=kvm     # qemu, kvm, esxi

		# 设置时间同步
		yum -y install chrony
		vim /etc/chrony.conf
		server 192.168.56.11 iburst

		保存退出

		timedatectl set-timezone Asia/Shanghai
		systemctl enable chronyd.service
		systemctl start chronyd.service

		chronyc sources # 对时间做同步

		# 启动计算节点服务
		systemctl enable libvirtd.service openstack-nova-compute.service
		systemctl restart libvirtd.service openstack-nova-compute.service



		# 在linux-node1 节点上面再次执行命令 openstack host list 会发现计算节点的主机名和对应组件
		openstack host list
		--------------------------------------------------------------------
		| Host Name                         | Service       | Zone         |
		--------------------------------------------------------------------
		| linux-node1.oldboyedu.com         | conductor     | internal     |
		| linux-node1.oldboyedu.com         | scheduler     | internal     |
		| linux-node1.oldboyedu.com         | consoleauth   | internal     |
		| linux-node1.oldboyedu.com         | cert          | internal     |
		| linux-node2.oldboyedu.com         | compute       | nova         |
		--------------------------------------------------------------------


		nova image-list # 测试nova节点连接glance组件是否正常
		-------------------------------------------------------------------------
		| ID                                       | Name   | Status  | Server  |
		-------------------------------------------------------------------------
		| 5f5058b0-209b-4e9d-a9e6-c15c09527454     | cirros | ACTIVE  |         |
		-------------------------------------------------------------------------

		nova endpoints # 发现启动正常
		......



	Neutron: 控制节点
		source admin-openrc.sh
		openstack service create --name neutron --description "OpenStack Networking" network
		openstack endpoint create --region RegionOne network public http://192.168.56.11:9696
		openstack endpoint create --region RegionOne network internal http://192.168.56.11:9696
		openstack endpoint create --region RegionOne network admin http://192.168.56.11:9696

		vim /etc/neutron/neutron.conf
		[database]
		connection = mysql://neutron:neutron@192.168.56.11:3306/neutron

		[keystone_authtoken]
		auth_uri = http://192.168.56.11:5000
		auth_uri = http://192.168.56.11:35357
		auth_plugin = password
		project_domain_id = default
		user_domain_id = default
		project_name = service
		username = neutron
		password = neutron

		[rabbit]
		rabbit_host = 192.168.56.11
		rabbit_port = 5672
		rabbit_userid = openstack
		rabbit_password = openstack

		[DEFAULT]
		core_plugin = ml2
		service_plugins = router

		notify_nova_on_port_status_changes = True
		notify_nova_on_port_data_changes = True
		nova_url = http://192.168.56.11:8774/v2

		[nova]
		auth_url = http://192.168.56.11:35357
		auth_plugin = password
		project_domain_id = default
		user_domain_id = default
		region_name = RegionOne
		project_name = service
		username = nova
		password = nova

		lock_path = $state_path/lock

		
		vim /etc/neutron/plugins/ml2/ml2_conf.ini
		[ml2]
		type_drivers = flat,vlan,gre,vxlan,geneve           # 支持的网络驱动
		tenant_network_types = vlan,gre,vxlan,geneve        # 支持的网络类型
		mechanism_drivers = openvswitch,linuxbridge
		extension_drivers = port_security

		[ml2_type_flat]
		flat_networks = physnet1

		[ml2_type_vlan]


		[ml2_type_gre]


		[ml2_type_vxlan]


		[ml2_type_geneve]


 		[securitygroup]
 		enable-ipset = True

 		保存退出


 		vim /etc/neutron/plugins/ml2/linuxbridge_agent.ini
 		[linux_bridge]
 		physical_interface_mappings = physnet1:eth0

 		[vxlan]
 		enable_vxlan = false

 		[agent]
 		prevent_arp_spoofing = True

 		[securitygroup]
 		firewall_driver = neutron.agent.linux.iptables_firewall.IptablesFirewallDriver
 		enable_security_group = True

 		保存退出


 		vim /etc/neutron/dhcp_agent.ini
 		[DEFAULT]
 		interface_driver = neutron.agent.linux.interface.BridgeInterfaceDriver
 		dhcp_driver = neutron.agent.linux.dhcp.Dnsmasq
 		enable_isolated_metadata = true
 		保存退出

		vim /etc/neutron/metadata_agent.ini
		[DEFAULT]
		auth_uri = http://192.168.56.11:5000
		auth_url = http://192.168.56.11:35357
		auth_region = RegionOne
		auth_plugin = password
		project_domain_id = default
		user_domain_id = default
		project_name = service
		username = neutron
		password = neutron

		保存退出

		vim /etc/nova/nova.conf
		[neutron]
		url = http://192.168.56.11:9696
		auth_url = http://192.168.56.11:35357
		auth_plugin = password
		project_domain_id = default
		user_domain_id = default
		region_name = RegionOne
		project_name = service
		username = neutron
		password = neutron
		service_metadata_proxy=true
		metadata_proxy_shared_secret=neutron

		保存退出

		ln -sv /etc/neutron/plugins/ml2/ml2_conf.ini /etc/neutron/plugin.ini

		source admin-openrc.sh
		openstack user create --domain default --password=neutron neutron
		openstack role add --project service --user neutron admin
		su -s /bin/sh -c "neutron-db-manage --config-file /etc/neutron/neutron.conf --config-file /etc/neutron/plugins/ml2/ml2_conf.ini upgrade head" neutron

		systemctl restart openstack-nova-api
		systemctl enable neutron-server.service neutron-linuxbridge-agent.service neutron-dhcp-agent.service neutron-metadata-agent.service
		systemctl start neutron-server.service neutron-linuxbridge-agent.service neutron-dhcp-agent.service neutron-metadata-agent.service

		neutron agent-list 



		# neutron linux-node2.example.com 上面的配置
		yum -y install openstack-neutron openstack-neutron-linuxbridge ebtables ipset
	
		在 linux-node1 上面将neutron的配置文件拷贝到linux-node2上面去
		scp -r /etc/neutron/neutron.conf  root@192.168.56.12:/etc/neutron/
		scp /etc/neutron/plugins/ml2/linuxbridge_agent.ini  root@192.168.56.12:/etc/neutron/plugins/ml2/
		scp /etc/neutron/plugins/ml2/ml2_conf.ini  root@192.168.56.12:/etc/neutron/plugins/ml2/

		# 编辑nova配置文件
		vim /etc/nova/nova.conf
		[neutron]
		url = http://192.168.56.11:9696
		auth_url = http://192.168.56.11:35357
		auth_plugin = password
		project_domain_id = default
		user_domain_id = default
		region_name = RegionOne
		project_name = service
		username = neutron
		password = neutron

		保存退出

		systemctl restart openstack-nova-compute
		ln -sv /etc/neutron/plugins/ml2/ml2_conf.ini  /etc/neutron/plugin.ini

		systemctl enable neutron-linuxbridge-agent.service
		systemctl start neutron-linuxbridge-agent.service


		在linux-node1 上面执行命令:
		neutron agent-list # 发现有节点的信息
		......



	------------------------------------------------------------------------------------------------------------------

	以上配置全部配置完成之后，设置neutron的桥接网络
	source admin-openrc.sh
	neutron net-create flat --shared --provider:physical_network physnet1 --provider:network_type flat
	......

	为网络创建一个子网
	neutron subnet-create flat 192.168.56.0/24 --name flat-subnet --allocation-pool start=192.168.56.100.end=192.168.56.200 --dns-nameserver 192.168.56.2 --gateway 192.168.56.2

	neutron subnet-list # 查看创建的子网
	neutron net-list
	----------------------------------------------------------------------------------------------------------------------------
	| id               | name    | cidr                                 | flat-subnet                                          |
	----------------------------------------------------------------------------------------------------------------------------
	| allocation_pools |         | 3c8fa76c-566c-466a-blc4-c8881d214655 | {"start": "192.168.56.100", "end": "192.168.56.200"} |
	----------------------------------------------------------------------------------------------------------------------------

	
	neutron net-list
	-------------------------------------------------------------------------------------------------------
	| id                                   | name  | subnets                                              |
	-------------------------------------------------------------------------------------------------------
	| b997c94b-64a9-4c64-96ed-7f972f3d329c | flat  | 3c8fa76c-566c-466a-blc4-c8881d214655 192.168.56.0/24 |
	-------------------------------------------------------------------------------------------------------


	使用demo用户创建虚拟机
	source demo-openrc.sh
	ssh-keygen -q -N ""
	ls /root/.ssh/
	......

	nova keypair -add --pub-key .ssh/id_rsa.pub mykey # 设置公钥
	nova keypair-list
	-----------------------------------------------------------
	| Name  | Fingerprint                                     |
	-----------------------------------------------------------
	| mykey | 6f:c6:53:d6:63:c1:86:d1:a2:30:c5:02:3b:72:4f:5b |
	-----------------------------------------------------------

	nova secgroup-add-rule default icmp -1 -1 0.0.0.0/0
	----------------------------------------------------------------
	| IP Protocol | From Port | To Port | IP Range  | Source Group |
	----------------------------------------------------------------
	| icmp        | -1        | -1      | 0.0.0.0/0 |              |
	----------------------------------------------------------------

	nova secgroup-add-rule default tcp 22 22 0.0.0.0/0
	----------------------------------------------------------------
	| IP Protocol | From Port | To Port | IP Range  | Source Group |
	----------------------------------------------------------------
	| tcp         | 22        | 22      | 0.0.0.0/0 |              |
	----------------------------------------------------------------

	
	# 配置完成之后就可以启动虚拟机了
	nova image-list
	---------------------------------------------------------------------
	| ID                                    | Name    | Status | Server |
	---------------------------------------------------------------------
	| 5f5058b0-209b-4e9d-a9e6-c15c09527454  | cirros  | ACTIVE |        |
	---------------------------------------------------------------------

	neutron net-list
	-------------------------------------------------------------------------------------------------------
	| id                                   | name  | subnets                                              |
	-------------------------------------------------------------------------------------------------------
	| b997c94b-64a9-4c64-96ed-7f972f3d329c | flat  | 3c8fa76c-566c-466a-blc4-c8881d214655 192.168.56.0/24 |
	-------------------------------------------------------------------------------------------------------

	nova boot --flavor ml.tiny --image cirros --nic-net-id=b997c94b-64a9-4c64-96ed-7f972f3d329c --security-group default --key-name mykey helloo-instance

	nova list
	----------------------------------------------------------------------------------------------------------------------
	| ID                                   | Name            | Status  | Task Status | Power State | Networks            |
	----------------------------------------------------------------------------------------------------------------------
	| 13b10a2d-30cf-47f7-ad9e-591685b2cdbb | hello-instance  | ACTIVE  | -           | Running     | flat=192.168.56.101 | 
	----------------------------------------------------------------------------------------------------------------------


	ping 192.168.56.101   # 发现可以ping通
	......


	ssh cirros@192.168.56.101   # 发现可以连接到该虚拟机
	......


	# 通过web界面打开虚拟机
	nova get-vnc-console helloo-instance novnc
	-----------------------------------------------------------------------------------------------
	| Type  | Url                                                                                 |
	-----------------------------------------------------------------------------------------------
	| novnc | http://192.168.56.11:6080/vnc_auto.html?token=726a8537-deae-4331-824f-aab48723645e  |
	-----------------------------------------------------------------------------------------------

	





